{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted Training Notebook\n",
    "A practical guide to the targeted training process. \n",
    "\n",
    "**Author:** Kalyan Dutia (kalyan.dutia@ibm.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we assume that you **already have your intents downloaded, in the `data/workspace_training` folder.** If you don't, you can manually download them or use the tool contained in the exploratory analysis notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external imports\n",
    "import os\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itables import show\n",
    "import logging\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# internal imports\n",
    "import config\n",
    "from cli_tools.get_intent_intersections import intent_intersections\n",
    "from cli_tools.diagnose_confusion import diagnose_confusion\n",
    "from conversation_test.kfoldtest import kfoldtest\n",
    "\n",
    "# config\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "logging.getLogger(\"requests\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"urllib3.connectionpool\").setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a skill\n",
    "If you can't see your skill here, check the `data/workspace_training` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onchange(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        clear_output()\n",
    "        display(d)\n",
    "        display_sample(d, 10)\n",
    "\n",
    "def display_sample(d, samplesize):\n",
    "    if samplesize != None:\n",
    "        display(Markdown(\"**<span style='color:blue'>{}</span>** skill selected. Training data sample:\".format(d.value)))\n",
    "    training_file = training_files[d.index]\n",
    "\n",
    "    train_df = pd.read_csv(os.path.join(config.training_dir, training_file), names=['utterance', 'intent'])\n",
    "    if (len(train_df) > 0) & (samplesize != None):\n",
    "        display(train_df.sample(samplesize))\n",
    "    elif samplesize:\n",
    "        display(Markdown(\"<span style='color:red'>No intent training data exists for this workspace</span>\"))\n",
    "    \n",
    "    return train_df\n",
    "\n",
    "training_files = [file for file in os.listdir(config.training_dir) if file.endswith('.csv')]\n",
    "d = widgets.Dropdown(options=[item[0:len(item)-14] for item in training_files])\n",
    "d.observe(onchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_we_are_interested_in = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(file_we_are_interested_in)\n",
    "train_df = display_sample(file_we_are_interested_in, 10)\n",
    "intents = train_df['intent'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the details of the workspace and instance in Watson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first set workspace given selection above\n",
    "train_df = display_sample(d, None)\n",
    "\n",
    "# INSTANCE. Use one of apikey or username & password\n",
    "apikey = \"\"\n",
    "url = \"https://api.eu-gb.assistant.watson.cloud.ibm.com\"\n",
    "\n",
    "# WORKSPACE \n",
    "workspace_id = \"a4b7589d-9f17-4875-9272-d6e34f2768a2\"\n",
    "threshold = 0.4\n",
    "\n",
    "# TEST PARAMS\n",
    "nfolds = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run K-Fold test\n",
    "In order to work out which intents to target, we first run a K-Fold test on our workspace.\n",
    "You can also directly run one using the module in the `conversation_test` folder.\n",
    "\n",
    "The kfold test returns:\n",
    "- `results_kfold`: the classification per utterances\n",
    "- `classification_report`: f1 score, accuracy, precision and recall per intent, as well as averages\n",
    "\n",
    "If you haven't already set the number of folds or the threshold, have a look at the bottom of the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "kfold = kfoldtest(apikey=apikey, url=url, n_folds=nfolds, threshold=threshold)\n",
    "kfold.intent_df_from_df(train_df)\n",
    "results_kfold, classification_report = kfold.full_run_kfold_from_df(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View worst performing intents\n",
    "We'll first choose a metric, then create a CSV showing the worst performing intents which can be used for annotation throughout this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"Now, we need to <span style='color:blue'>choose which metric to prioritise for this workspace.</span>\" \n",
    "\n",
    "\"\\n \\n If FPs and FNs are equally negative, then you may want to look at F1 score. More on this in **Section x** of the training at scale guide.\"\n",
    "\n",
    "\"\\n \\n**Preferred metric:**\"))\n",
    "        \n",
    "d_m = widgets.Dropdown(options=['precision', 'recall', 'accuracy', 'F1'])\n",
    "display(d_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_rep_export = classification_report.loc[intents, :].sort_values(d_m.value, ascending=True)\n",
    "cl_rep_export = cl_rep_export.drop(columns='set size')\n",
    "\n",
    "intent_sizes = train_df.groupby('intent').count()\n",
    "cl_rep_export['train_size'] = intent_sizes\n",
    "\n",
    "cl_rep_export['comment'] = \"\"\n",
    "cl_rep_export['action'] = \"\"\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M\")\n",
    "filename = d.value + '_kfold_results_' + timestr + '.csv'\n",
    "output_path = os.path.join(config.output_folder, filename)\n",
    "cl_rep_export.to_csv(output_path)\n",
    "\n",
    "display(Markdown(\"We can then view K-fold results sorted by this metric, with a column added to show the size of the training set, and a couple more for annotation.\"))\n",
    "display(Markdown(\"These results have been exported to <span style='color:blue'>{}</span> for annotation throughout the targeted training process.\".format(output_path)))\n",
    "display(cl_rep_export)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(Markdown(\"We can also view a plot of these.\"))\n",
    "melt_df = cl_rep_export.reset_index().melt(id_vars=['index'], value_vars=['F1', 'accuracy', 'precision', 'recall']).rename(columns={'confusion': 'metric'})\n",
    "ax = sns.catplot(data=melt_df, col_wrap=2, x='index', y='value', col='metric', kind='bar', hue=\"metric\")\n",
    "[plt.setp(ax.get_xticklabels(), rotation=80) for ax in ax.axes.flat];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Root Cause\n",
    "The next stage is to write some comments and actions for the training that is needed. To do this we'll use the tools in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More training?\n",
    "A common sign that an intent needs more training is that it has **low recall**: it is commonly not matching intents with enough confidence to provide a response. To test for this we can plot recall against training set size for our intents. \n",
    "\n",
    "You should investigate any intents which fall on the bottom left hand size of this plot as candidates for getting more training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lmplot(data=cl_rep_export, x='train_size', y='recall', fit_reg=False)\n",
    "ax.axes[0,0].set_title('Intent Size vs Recall')\n",
    "ax.axes[0,0].set_ylim(0,1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intent Overlaps\n",
    "Here we'll use tools to find overlapping phrases between intents that may be causing confusion between them. \n",
    "\n",
    "Change the parameters in the next cell to choose the length of the ngrams being searched for, and whether to remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_list = [4,5] \n",
    "stopwords = '_none' # stopwords_in can be none, nltk, or config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = intent_intersections(ngram_list, stopwords_in=stopwords, intent_col='intent')\n",
    "ii.import_training_df(train_df)\n",
    "intersection_df, intersection_size_df = ii.calculate_ngram_intersections()\n",
    "\n",
    "intersection_size_df = intersection_size_df.fillna(0)\n",
    "heatmap_colors = sns.cubehelix_palette(8, start=2, rot=0, dark=0.2, light=.95, reverse=False)\n",
    "ax = sns.heatmap(intersection_size_df, annot=True, cmap=heatmap_colors, cbar=False, square=True)\n",
    "ax.set_title('Intent Overlap Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can look into specific overlaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onchange(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        clear_output()\n",
    "        display(d01)\n",
    "        display(d02)\n",
    "        display_intent_overlap(d01.value, d02.value)\n",
    "\n",
    "def display_intent_overlap(intent1, intent2):\n",
    "    if d01.value != d02.value:\n",
    "        ngrams_per_intent_df, ngram_freq_df = ii.get_ngrams_per_intent()\n",
    "        overlap_df = ii.get_intersection_freqs([intent1, intent2], ngram_freq_df)\n",
    "        overlap_df = overlap_df.sort_values([intent1, intent2], ascending=False)\n",
    "        display(overlap_df)\n",
    "    else:\n",
    "        display(Markdown(\"Intents chosen can't be the same\"))\n",
    "\n",
    "d01 = widgets.Dropdown(options=train_df['intent'].unique())\n",
    "d02 = widgets.Dropdown(options=train_df['intent'].unique())\n",
    "\n",
    "d01.observe(onchange)\n",
    "d02.observe(onchange)\n",
    "\n",
    "display(d01)\n",
    "display(d02)\n",
    "display_intent_overlap(d01.value, d02.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"You can use the table below to search through training utterances.\"))\n",
    "show(train_df[['utterance', 'intent']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnose Confusion\n",
    "You can also find training utterances that may have caused misclassifications, by entering an utterance that has been misclassified.\n",
    "Note that the list produced is only a guide which will find the most obvious samples (no stemming or lemmatisation), and in no way exhaustive.\n",
    "\n",
    "You should also use the table above to search for different forms of words in the utterance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_list = [1,2,3,4]\n",
    "stopwords = None # None, 'nltk', or 'config'\n",
    "\n",
    "######################\n",
    "## DON'T EDIT BELOW ##\n",
    "######################\n",
    "def handle_submit(obj):\n",
    "    clear_output()\n",
    "    display(text_in)\n",
    "    display( diagnose_confusion(obj.value, d.value, n_list, stopwords) )\n",
    "\n",
    "text_in = widgets.Text()\n",
    "display(text_in)\n",
    "text_in.on_submit(handle_submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of 'training' will fall into one of three categories: resolving clashes, cleaning training data, or getting more training data. \n",
    "\n",
    "See the last section of the Training at Scale guide for tips on how to improve your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}